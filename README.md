# ðŸ¤– Introduction to Machine Learning Labs (DS3010)

### ðŸ“˜ Course Overview
A comprehensive, hands-on journey through **core Machine Learning concepts**, focused on both **theory and implementation** using Python and scikit-learn.  
Each lab emphasizes coding from scratch, visualization, and model evaluation to build strong practical understanding.

**Student:** Parv Patel  
**Roll No:** 142301041  
**Institution:** Department of Data Science , Indian Institute of Palakkad  
**Duration:** Aug â€“ Nov 2025  

---

## Skills & Concepts Covered

| Category | Topics |
|-----------|--------|
| **Programming Foundations** | Python, NumPy, SciPy, Matplotlib, Pandas |
| **Regression** | Linear Regression, Ridge Regression, Nonlinear Regression, Standardization |
| **Classification** | Logistic Regression (from scratch), Naive Bayes, Support Vector Machines (SVM) |
| **Model Evaluation** | Cross-validation, LOO Error, ROC, Performance Metrics |
| **Ensemble Learning** | Decision Trees, Bagging, Boosting, Random Forests |
| **Dimensionality Reduction** | Principal Component Analysis (PCA) |
| **Clustering** | K-Means, Gaussian Mixture Model (GMM), Expectation Maximization, DBSCAN |
| **Sequential Models** | Hidden Markov Models (HMM) |
| **ML Pipeline Skills** | Data preprocessing, Feature scaling, Visualization, Model comparison |

---

## Weekly Lab Breakdown

| Week | Lab Title | Key Focus | 
|------|------------|------------|
| **1** | Python and NumPy | Python logic, data structures, NumPy arrays, Matplotlib basics | 
| **2** | SciPy and Pandas | Data analysis & statistics using SciPy and Pandas | 
| **3** | Linear Regression & Standardization | Understanding feature scaling impact on regression coefficients | 
| **4** | Ridge & Nonlinear Regression | Cross-validation, polynomial regression, overfitting control | 
| **5** | Logistic Regression & Naive Bayes | Implementing Logistic Regression from scratch and GaussianNB | 
| **6** | Kernel SVM | Linear & RBF kernels, decision boundaries, parameter tuning | 
| **7** | Decision Tree & Random Forest | Model interpretability and ensemble averaging | 
| **8** | Principal Component Analysis (PCA) | Dimensionality reduction and explained variance | 
| **9** | Clustering (KMeans, GMM, DBSCAN) | Unsupervised learning and density-based clustering | 
| **10** | Hidden Markov Model (HMM) | Sequential probability modeling and Viterbi decoding | 

---

## Tools & Libraries

- **Languages:** Python 3.x  
- **Libraries:** NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn, SciPy, hmmlearn  
- **Environment:** Jupyter Notebook (Anaconda)  
- **Version Control:** Git & GitHub  

---

## Learning Highlights

Built ML models **from scratch** to strengthen algorithmic understanding.  
Gained hands-on experience with **data preprocessing, visualization, and model tuning**.  
Learned to apply **cross-validation and regularization** for better generalization.  
Explored both **supervised and unsupervised** ML approaches.  
Applied **dimensionality reduction and clustering** for pattern discovery.  
Implemented **probabilistic sequential modeling** using HMMs.

---
## Repository Structure

DS3010_Intro_to_ML
â”£ Lab1_Python_and_NumPy
â”£ Lab2_Intro_to_Pandas_and_SciPy
â”£ Lab3_Linear_Regression_and_Standardization
â”£ Lab4_Ridge_and_Nonlinear_Regression
â”£ Lab5_Logistic_Regression_and_Naive_Bayes
â”£ Lab6_Kernel_SVM_and_Classification
â”£ Lab7_Decision_Tree_and_Random_Forest
â”£ Lab8_Principal_Component_Analysis
â”£ Lab9_Clustering_KMeans_GMM_DBSCAN
â”£ Lab10_Hidden_Markov_Model
â”— README.md



Each lab folder contains:
- The corresponding `.ipynb` notebook  
- A detailed `README.md` describing objectives, tasks, and outcomes  

---

## Reference Materials
- *Pattern Recognition and Machine Learning* â€“ Christopher M. Bishop  
- *The Elements of Statistical Learning* â€“ Hastie, Tibshirani, Friedman  
- *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* â€“ AurÃ©lien GÃ©ron  
- *Introduction to Machine Learning with Python* â€“ Andreas MÃ¼ller, Sarah Guido  

---

## Summary
This repository represents **a complete, practical foundation in Machine Learning**, covering the entire workflow â€”  
from mathematical intuition and data preprocessing to advanced model development, evaluation, and visualization.  
Every lab reinforced real-world implementation skills and algorithmic intuition.

---

**Contact:**  
[parv4careers@gmail.com]  
[LinkedIn](https://www.linkedin.com/in/parvptl/) | [GitHub](https://github.com/Parvptl)  

*"Building intelligence, one lab at a time."*

